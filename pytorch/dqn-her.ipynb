{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit flipping environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitFlipEnv():\n",
    "    \n",
    "    def __init__(self, n = 8):\n",
    "        self.n = n\n",
    "        self.init_state = torch.randint(2, size=(n,))\n",
    "        self.target_state = torch.randint(2, size=(n,))\n",
    "        while np.array_equal(self.init_state, self.target_state):\n",
    "            self.target_state = torch.randint(2, size=(n,))\n",
    "        self.curr_state = self.init_state.clone()\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.curr_state[action] = 1 - self.curr_state[action]\n",
    "        if np.array_equal(self.curr_state, self.target_state):\n",
    "            return self.curr_state.clone(), 0\n",
    "        else:\n",
    "            return self.curr_state.clone(), -1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.init_state = torch.randint(2, size=(self.n,))\n",
    "        self.target_state = torch.randint(2, size=(self.n,))\n",
    "        while np.array_equal(self.init_state, self.target_state):\n",
    "            self.target_state = torch.randint(2, size=(self.n,))\n",
    "        self.curr_state = self.init_state.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BitFlipEnv(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: tensor([ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.])\n",
      "Target state: tensor([ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  1.])\n",
      "State, reward after taking action 9: tensor([ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  0.]) -1\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('Initial state:', env.init_state)\n",
    "print('Target state:', env.target_state)\n",
    "curr_state, reward = env.step(9)\n",
    "print('State, reward after taking action 9:', curr_state, reward)\n",
    "print(type(curr_state))\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', \n",
    "                       ('state', 'action', 'next_state', 'reward', 'goal'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity = 1e5):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "    \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition which should contain:\n",
    "        - current state\n",
    "        - action taken\n",
    "        - next state\n",
    "        - reward obtained\n",
    "        - goal state\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "        if len(self.memory) > self.capacity:\n",
    "#             print('!!!!!memory capacity exceeded!')\n",
    "            del self.memory[0]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns batch_size number of samples from the replay memory\n",
    "        \"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS = 15\n",
    "HIDDEN_SIZE = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.ln1 = nn.Linear(NUM_BITS*2, HIDDEN_SIZE)\n",
    "        self.ln2 = nn.Linear(HIDDEN_SIZE, NUM_BITS)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "\n",
    "TARGET_UPDATE = 50\n",
    "MODEL_PATH = '_her_policy_net.pt'\n",
    "WEIGHTS_PATH = '_her_policy_net_weights.pt'\n",
    "FIGURE_PATH = '_her.png'\n",
    "SAVE_MODEL = True\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = FNN().to(device)\n",
    "target_net = FNN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, goal, greedy=False):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    state_goal = torch.cat((state, goal))\n",
    "#     print(state)\n",
    "#     print(goal)\n",
    "#     print(state_goal)\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "#     if steps_done % 1000 == 0:\n",
    "#         print('Steps done: {} Epsilon threshold: {}'.format(steps_done, eps_threshold))\n",
    "    if greedy:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state_goal).argmax().view(1,1)\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state_goal).argmax().view(1,1)\n",
    "    else: \n",
    "        return torch.tensor([[random.randrange(NUM_BITS)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "#     print(transitions)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "#     print(batch)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, \n",
    "                                           batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state \n",
    "                                      if s is not None])\n",
    "    \n",
    "    \n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    goal_batch = torch.stack(batch.goal)\n",
    "    state_goal_batch = torch.cat((state_batch, goal_batch), 1)\n",
    "    non_final_next_states_goal = torch.cat((non_final_next_states, goal_batch), 1)\n",
    "    \n",
    "    state_action_values = policy_net(state_goal_batch).gather(1, action_batch)\n",
    "    \n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states_goal).max(1)[0].detach()\n",
    "    \n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.float()\n",
    "    \n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HindsightTransition = namedtuple('HindsightTransition', \n",
    "                       ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7491.296875"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory)/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 2000 3000 4000 5000 6000 7000 "
     ]
    }
   ],
   "source": [
    "for i in range(int(len(memory)/BATCH_SIZE)):\n",
    "    optimize_model()\n",
    "    if i % 1000 == 0:\n",
    "        print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_RATE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 20000\n",
    "EPS_DECAY = num_episodes * NUM_BITS * 0.25\n",
    "env = BitFlipEnv(NUM_BITS)\n",
    "success = 0\n",
    "episodes = []\n",
    "success_rate = []\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    state = env.init_state\n",
    "    goal = env.target_state\n",
    "    transitions = []\n",
    "    episode_success = False\n",
    "    for t in range(NUM_BITS):\n",
    "        if episode_success:\n",
    "            continue\n",
    "        action = select_action(state, goal)\n",
    "        next_state, reward = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        memory.push(state, action, next_state, reward, goal)\n",
    "        \n",
    "        transitions.append(HindsightTransition(state, action, next_state, reward))\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        optimize_model()\n",
    "        if reward == 0:\n",
    "            if episode_success:\n",
    "                continue\n",
    "            else:\n",
    "                episode_success = True\n",
    "                success += 1\n",
    "    if not episode_success:\n",
    "        new_goal_state = state.clone()\n",
    "#         print('Hindsight experience')\n",
    "        if not np.array_equal(new_goal_state, goal):\n",
    "            for i in range(NUM_BITS):\n",
    "                if np.array_equal(transitions[i].next_state, new_goal_state):\n",
    "                    memory.push(transitions[i].state, transitions[i].action, transitions[i].next_state, torch.tensor([0]), new_goal_state)\n",
    "                    optimize_model()\n",
    "                    break\n",
    "\n",
    "                memory.push(transitions[i].state, transitions[i].action, transitions[i].next_state, transitions[i].reward, new_goal_state)\n",
    "                optimize_model()\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "#         print(i_episode, end=' ')\n",
    "    if i_episode % CHECK_RATE == 0:\n",
    "        print('success rate for last {} episodes after {} episodes of training: {}%'.format(CHECK_RATE, i_episode, success/CHECK_RATE * 100))\n",
    "        success_rate.append(success/CHECK_RATE)\n",
    "        episodes.append(i_episode)\n",
    "        success = 0\n",
    "\n",
    "episodes.append(num_episodes)\n",
    "success_rate.append(success/CHECK_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_DECAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.plot(episodes, success_rate)\n",
    "plt.title('HER performance on N={} bits'.format(NUM_BITS))\n",
    "plt.ylabel('Success Rate')\n",
    "plt.xlabel('Number of Episodes')\n",
    "plt.ylim([0, 1])\n",
    "if SAVE_MODEL:\n",
    "    plt.savefig(str(NUM_BITS)+FIGURE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_MODEL:\n",
    "    torch.save(policy_net.state_dict(), str(NUM_BITS)+WEIGHTS_PATH)\n",
    "    print('Weights saved')\n",
    "    torch.save(policy_net, str(NUM_BITS)+MODEL_PATH)\n",
    "    print('Model saved')\n",
    "\n",
    "print('Complete')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False\n",
    "if LOAD_MODEL:\n",
    "    policy_net.load_state_dict(torch.load('final_weights/'+str(NUM_BITS)+WEIGHTS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "successes = 0\n",
    "for i in range(100):\n",
    "    env.reset()\n",
    "    test_state = env.init_state\n",
    "    goal_state = env.target_state\n",
    "#     print('#############################################')\n",
    "#     print('start', test_state)\n",
    "#     print('goal', goal_state)\n",
    "    next_state = test_state.clone()\n",
    "    for i in range(NUM_BITS):\n",
    "        action = select_action(next_state, goal_state, greedy=True)\n",
    "        next_state, reward = env.step(action.item())\n",
    "#         print('taking action', action)\n",
    "#         print('next state', next_state)\n",
    "        if np.array_equal(next_state, goal_state):\n",
    "            successes += 1\n",
    "            break\n",
    "print(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
